<!DOCTYPE html>
<html class="">
  <head>
    <meta charset="UTF-8">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Personal portfolio powered by Jekyll and GitHub Pages ">
    <meta rel="author" href="https://plus.google.com/u/0/#">
    <meta rel="publisher" href="https://plus.google.com/u/0/#">
    <title>
      
        Deep Learning With PyTorch, Part 2: Fundamentals | Nick Hunkins
      
    </title>
    <link rel="stylesheet" href="/assets/css/all.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
    <!--[if lt IE 9]><script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
    <!-- Use Atom -->
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Nick Hunkins" />
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-112060364-3', 'auto');
  ga('send', 'pageview');
</script>


    <!-- Use Jekyll SEO plugin -->
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Deep Learning With PyTorch, Part 2: Fundamentals | Nick Hunkins</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Deep Learning With PyTorch, Part 2: Fundamentals" />
<meta name="author" content="Nick Hunkins" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Nick Hunkins’ personal website - Powered by Jekyll and GitHub Pages" />
<meta property="og:description" content="Nick Hunkins’ personal website - Powered by Jekyll and GitHub Pages" />
<link rel="canonical" href="http://localhost:4000/pytorch-fundamentals" />
<meta property="og:url" content="http://localhost:4000/pytorch-fundamentals" />
<meta property="og:site_name" content="Nick Hunkins" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-08-16T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Deep Learning With PyTorch, Part 2: Fundamentals" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Nick Hunkins"},"dateModified":"2024-08-16T00:00:00-06:00","datePublished":"2024-08-16T00:00:00-06:00","description":"Nick Hunkins’ personal website - Powered by Jekyll and GitHub Pages","headline":"Deep Learning With PyTorch, Part 2: Fundamentals","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/pytorch-fundamentals"},"url":"http://localhost:4000/pytorch-fundamentals"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <div class="site-container">
      <header>
  <div class="logo" style="width:250px;">
    <a href="/"><p style="font-size:26px;color:#716262;">Nick Hunkins</p></a>
  </div>
  <nav>
    
      <a href="/"><p style="font-variant:small-caps;color:#716262;">home</p></a>
    
      <a href="/blog"><p style="font-variant:small-caps;color:#716262;">blog</p></a>
    
      <a href="/about"><p style="font-variant:small-caps;color:#716262;">about</p></a>
    
      <a href="/contact"><p style="font-variant:small-caps;color:#716262;">contact</p></a>
    
  </nav>
  <hr>
</header>

      <section>
  <div class="post-container">
    <h4 class="project-title"></h4>
    <div class="project-load"><head>
  <link rel="stylesheet" href="../assets/css/blogstyles.css" />
</head>

<h1 id="deep-learning-with-pytorch">Deep Learning With PyTorch</h1>

<h2 id="part-2-fundamentals">Part 2: Fundamentals</h2>

<h4 id="what-is-a-tensor">What Is A Tensor?</h4>

<p>Mathematically, a <a href="https://en.wikipedia.org/wiki/Tensor">tensor</a> is an algebraic object that describes the relationship between its elements as it pertains to a vector space. That sounds like a lot, but it’s actualy not so complicated. You can think of a tensor as an extension of a multidimensional array where each element within the array is a vector.</p>

<p>If that’s confusing and abstract, don’t worry. We can leave the exact definition of a tensor to the mathematicians. The point is that tensors are similar to multidimensional arrays, but have a few extra perks that make them ideal for representing deep neural networks.</p>

<h4 id="tensors-in-pytorch">Tensors in PyTorch</h4>

<p>A PyTorch tensor is very similar to NumPy array. They can hold similar data structures and even share the same syntax for indexing. However, PyTorch tensors come with a couple of crucial bonus features:</p>
<ul>
  <li><strong>Device Flexibility</strong>: Tensors can be moved easily between the CPU and GPU to optimize your workflow.</li>
  <li><strong>Autograd Support</strong>: PyTorch tensors can automatically keep track of the operations performed on them, an essential feature for backpropagation.</li>
</ul>

<h3 id="note">NOTE</h3>
<p class="center"><i>While I will include sample code snippets with this post, I will not include much output. This is on purpose! The best thing to learn quickly is to try these code snippets out for yourself and see what happens!</i></p>
<p><br />
<br /></p>

<h4 id="creating-tensors">Creating Tensors</h4>

<p>Tensors can be made in multiple ways. Below are a few of the most common methods. Before we do anything, let’s import the PyTorch library</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch
</code></pre></div></div>

<h5 id="scalars">Scalars</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scalar = torch.tensor(7)
</code></pre></div></div>

<h5 id="vectors">Vectors</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vector = torch.tensor([7, 7])
</code></pre></div></div>

<h5 id="matrices">Matrices</h5>
<ul>
  <li>Note that matrix variable names are capitalized by convention.</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MATRIX = torch.tensor([[7, 7],
                       [7, 7]])
</code></pre></div></div>

<h5 id="tensors-of-ones-zeros--random-values">Tensors of Ones, Zeros, &amp; Random Values</h5>
<p>We can make tensors filled with ones, zeros, or random values in a single line. All we need to do is pass in the dimensions we want of the output tensor.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ones = torch.ones(size=(3, 4))
zeros = torch.zeros(size=(1, 2, 3, 4))
random = torch.randn(size=(3, 20, 20))
</code></pre></div></div>

<h5 id="other-useful-methods---arange--like">Other Useful Methods - arange &amp; like</h5>

<p><code class="language-plaintext highlighter-rouge">torch.arange(start, stop, step)</code> - Create a tensor populated with values ranging from <i>start</i> to <i>stop</i> at incrememnts of size <i>step</i></p>

<p><code class="language-plaintext highlighter-rouge">torch.zeros_like(input=other_tensor)</code> - Create a tensor of zeros (could be ones or randn) with the same shape as the input tensor</p>

<h4 id="working-with-tensors">Working With Tensors</h4>

<p>If tensors are going to do all the heavy lifting for our DNNs, then we better know how to work with them and how they can interact with each other. Here are some of the most common tensor operations, aggregations, and transformations. :</p>

<h5 id="common-operations">Common Operations</h5>
<ul>
  <li>Addition (<code class="language-plaintext highlighter-rouge">+</code>):
    <ul>
      <li>Add a scalar to each element of a tensor or element-wise addition of two tensors of the same shape.</li>
      <li><code class="language-plaintext highlighter-rouge">A + B</code></li>
      <li><code class="language-plaintext highlighter-rouge">A + c</code></li>
    </ul>
  </li>
  <li>Subtraction (<code class="language-plaintext highlighter-rouge">-</code>):
    <ul>
      <li>Subtract a scalar from each element of a tensor or element-wise subtraction of two tensors of the same shape.</li>
      <li><code class="language-plaintext highlighter-rouge">A - B</code></li>
      <li><code class="language-plaintext highlighter-rouge">A - c</code></li>
    </ul>
  </li>
  <li>Multiplication (<code class="language-plaintext highlighter-rouge">*</code>):
    <ul>
      <li>Multiply each element of a tensor by a scalar or element-wise multiplication of two tensors of the same shape.</li>
      <li><code class="language-plaintext highlighter-rouge">A * B</code></li>
      <li><code class="language-plaintext highlighter-rouge">A * c</code></li>
    </ul>
  </li>
  <li>Division (<code class="language-plaintext highlighter-rouge">/</code>):
    <ul>
      <li>Divide each element of a tensor by a scalar or element-wise division of two tensors of the same shape.</li>
      <li><code class="language-plaintext highlighter-rouge">A / B</code></li>
      <li><code class="language-plaintext highlighter-rouge">A / c</code></li>
    </ul>
  </li>
  <li>Matrix Multiplication (<code class="language-plaintext highlighter-rouge">@</code>):
    <ul>
      <li>Matrix multiplication between two tensors with matching inner dimensions (i.e. <code class="language-plaintext highlighter-rouge">[m x n] @ [n x k]</code> )</li>
      <li><code class="language-plaintext highlighter-rouge">A @ B</code></li>
      <li><code class="language-plaintext highlighter-rouge">torch.matmul(A, B)</code></li>
    </ul>
  </li>
</ul>

<h5 id="aggregations">Aggregations</h5>
<ul>
  <li>Min
    <ul>
      <li>Return the minimum value in a tensor</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.min()</code></li>
    </ul>
  </li>
  <li>Max
    <ul>
      <li>Return the maximum value in a tensor</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.max()</code></li>
    </ul>
  </li>
  <li>Mean
    <ul>
      <li>Return the mean value of a tensor</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.mean()</code></li>
    </ul>
  </li>
  <li>Sum
    <ul>
      <li>Return the sum of values in a tensor</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.sum()</code></li>
    </ul>
  </li>
</ul>

<h5 id="tensor-transformations">Tensor Transformations</h5>
<ul>
  <li>Reshape
    <ul>
      <li>Reshape input tensor to specified new dimensions ()</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.reshape(9, 1)</code></li>
    </ul>
  </li>
  <li>View
    <ul>
      <li>Similar to reshape, but <strong>shares the same memory</strong> as the original tensor ()</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.view(9, 1)</code></li>
    </ul>
  </li>
  <li>Permute
    <ul>
      <li>Return a view of a tensor with dmensions permuted (swapped) in a certain way</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.permute(2, 0, 1)</code> (dim0-&gt; dim1, dim2-&gt; dim0, dim1-&gt; dim2)</li>
    </ul>
  </li>
  <li>Stack
    <ul>
      <li>Combine multiple tensors along a specified dimension (default=0)</li>
      <li><code class="language-plaintext highlighter-rouge">torch.stack([tensor1, tensor2, tensor3])</code></li>
    </ul>
  </li>
  <li>Squeeze
    <ul>
      <li>Removes all dimensions of size 1 from the tensor</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.squeeze()</code></li>
    </ul>
  </li>
  <li>Unsqueeze
    <ul>
      <li>Adds a dimension of size 1 to the tensor in specified index</li>
      <li><code class="language-plaintext highlighter-rouge">tensor.unsqueeze(dim=0)</code></li>
    </ul>
  </li>
</ul>

<h4 id="indexing-into-tensors">Indexing into Tensors</h4>

<p>The creators of PyTorch worked hard to ensure that their library was easy to learn if you already are familiar with other technologies in the data work world. Luckily for us, that means that if you’re comfortable slicing and dicing multidimensional arrays in NumPy, then you’ll find the same syntax works for slicing and indexing into PyTorch Tensors.</p>

<p>Consider the following tensor:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A = [[1, 2, 3]
     [4, 5, 6]
     [7, 8, 9]]
</code></pre></div></div>

<ul>
  <li>Indexing
    <ul>
      <li><code class="language-plaintext highlighter-rouge">A[0] --&gt; tensor([1, 2, 3])</code></li>
      <li><code class="language-plaintext highlighter-rouge">A[0][0] --&gt; tensor(1)</code></li>
    </ul>
  </li>
  <li>Slicing
    <ul>
      <li><code class="language-plaintext highlighter-rouge">A[1][0:2] --&gt; tensor([4, 5])</code></li>
    </ul>
  </li>
</ul>

<h4 id="thanks">Thanks!</h4>

<p>That’s it for this whirlwind tour of the basic knowledge needed to work with tensors in PyTorch. For a deeper look, check out the <a href="https://pytorch.org/docs/stable/">Official Documentation</a> and <a href="https://pytorch.org/tutorials/beginner/ptcheat.html"> PyTorch Cheat Sheet</a>. My writing here is meant as a primer to familiarize you with essential concepts. I encourage you now (and in the future) to always check the official resources to learn more!</p>

<h3 id="continue-reading-part-3-basic-pytorch-workflow--"><a href="pytorch-workflow">Continue Reading Part 3: Basic PyTorch Workflow -&gt;</a></h3>

<h3 id="--go-back-to-part-1-a-gentle-introduction"><a href="pytorch-introduction">(&lt;- Go Back to Part 1: A Gentle Introduction)</a></h3>
</div>
  </div>
  
</section>

      <footer>
  <div class="footer-wrap">
    <div class="footer-tagline">
      <p></p>
    </div>
    <div class="social-media">
      <nav>
        
          <a href="https://instagram.com/nick.hunkins" target="_blank"><i class="fa fa-instagram" aria-hidden="true"></i></a>
        
          <a href="https://github.com/nchp89" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
        
          <a href="https://linkedin.com/in/nick-hunkins" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
        
          <a href="mailto:nickhunkins@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
        
      </nav>
    </div>
  </div>
</footer>

    </div>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
  </body>
</html>
